视频链接：https://morvanzhou.github.io/tutorials/data-manipulation/np-pd/

numpy和pandas区别
1、numpy序列化数据
2、pandas相当于字典形式的numpy 

1、创建 Series or DataFrame及pandas的基本操作
	import pandas as pd
	import numpy as np
	
	1.1 创建Series
		s = pd.Series([1,3,6,np.nan,44,1])
		
		dates = pd.date_range('20160101',periods=6)  # 生成六个日期
			 >>   DatetimeIndex(['2016-01-01', '2016-01-02', '2016-01-03', '2016-01-04',
				   '2016-01-05', '2016-01-06'],dtype='datetime64[ns]', freq='D')
	1.2 创建DataFrame
		# 定义1：创建DataFrame
		df = pd.DataFrame(np.random.randn(6,4),index=dates,columns=['a','b','c','d'])
		  #DataFrame注意要大写的字母。用dates做行索引，用a,b,c,d做列索引
			index表行索引 columns表列索引
		
		# 定义2：用字典形式导入
		 df = pd.DataFrame({'A':1,
					'B':pd.Timestamp('20131002'),
					'C':pd.Series(1,index=list(4)),dtype='float32'),
					'D':np.array([3]*4,dtype='int32')}	
		
	1.3 pandas常见的基本操作
		df.dtypes            #查看每一列的数据类型
		df.index  			 #查看每一行的行名
		df.columns  		 #打印每一列的列名
		df.values            #查看表的值
		df.describe()		 #查看表中数字型的数字，忽略字符串
		df.T   				 #把DataFrame当做矩阵，进行转置
		df.sort_index(axis=1,ascending=False)  #对列名进行倒排序
		df.sort_values(by='列名')              #对某一列值进行排序
		 

2、 选择数据
    dates = pd.date_range('20130101', periods=6)
	df = pd.DataFrame(np.arange(24).reshape((6,4)),index=dates, columns=['A','B','C','D'])
	
	2.1 选择某一列 (查看某一列)
	    df['A']  或 df.A   #A代表列名
		
	2.2 从0到第3行 (查看前n行  df[0:n])
	    df[0:3]
		
	2.3 df.loc['A']   # 另一种查看某一行的方法，A表示行名称
	
	2.4  df[:,['A','B']]     # 打1:3]
	
3、
		dates = pd.date_range('20130101', periods=6)
		df = pd.DataFrame(np.arange(24).reshape((6,4)),index=dates, columns=['A','B','C','D'])
		df.iloc[0,1] = np.nan
		df.iloc[1,2] = np.nan
		"""
					 A     B     C   D
		2013-01-01   0   NaN   2.0   3
		2013-01-02   4   5.0   NaN   7
		2013-01-03   8   9.0  10.0  11
		2013-01-04  12  13.0  14.0  15
		2013-01-05  16  17.0  18.0  19
		2013-01-06  20  21.0  22.0  23
		"""
	3.1 pd.dropna()
		如果想直接去掉有 NaN 的行或列, 可以使用 dropna
		
		df.dropna(
				axis=0,     # 0: 对行进行操作; 1: 对列进行操作
				how='any'   # 'any': 只要存在 NaN 就 drop 掉; 'all': 必须全部是 NaN 才 drop 
				) 
		"""
					 A     B     C   D
		2013-01-03   8   9.0  10.0  11
		2013-01-04  12  13.0  14.0  15
		2013-01-05  16  17.0  18.0  19
		2013-01-06  20  21.0  22.0  23

8 DataFrame数据可视化
	import pandas as pd
	import numpy as np
	import matplotlib as plt
	# plot data
	
	8.1 创建一个线性数据 Series
		# Series
		data = pd.Series(np.random.randn(1000),index=np.arange(1000))
		data = data.cumsum() # 累加
		data.plot()
		#plt.plot(数据)
		plt.show()
	
	8.2 将Dataframe(类似矩阵形式)可视化
		#scatter(x=**,y=**)方法
		data = pd.DataFrame(
			np.random.randn(1000,4),
			index=np.arange(1000),
			columns=list("ABCD")
			)
		data = data.cumsum()
		ax = data.plot.scatter(x='A',y='B',color='red',label='Calss1')
		# 将之下这个 data 画在上一个 ax 上面
		data.plot.scatter(x='A',y='C',color='LightGreen',label='Class2',ax=ax)
		plt.show()
	
	
	参数： 
		1、plot参数： matplotlib.pyplot.plot(*args, **kwargs)
				plot(x, y)        # 绘制x和y使用默认线条样式和颜色
				plot(x, y, 'bo')  # 绘制使用蓝色圆圈标记的x和y
				plot(y)           # plot y使用x作为索引数组0..N-1
				plot(y, 'r+')     # 同上，但用红色的
			np.random.rand(raw,column) 两个参数行、列
			eg: np.random.rand(3,2)   #随机产生三行两列的数据
		2、matplotlib.pyplot.scatter(x,y,c='r',s= 100,linewidths=lValue,marker='o')
			 c='**'         ：设置颜色 red、blue、green、black、yellow、cyan。。。
							:可用简写  'r','y','g','b','r','y','g','b','r'
			 s='**'         : 
			 linewidths='**': 设置线宽
			 marker='**'    ：
			 
		3、
		

%%%%%%%%%%%%%%%%%%%下面是在实际使用时，自己不会去查找的知识点及链接%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%% 温故而知新，可以为师矣%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

1、pd.read_csv()的各个参数  <http://www.cnblogs.com/datablog/p/6127000.html>
   
   1.1 names : array-like, default None
	  用于结果的列名列表，如果数据文件中没有列标题行，就需要执行header=None。默认列表中不能
	  出现重复，除非设定参数mangle_dupe_cols=True。
   
   1.2 dtype : Type name or dict of column -> type, default None
      每列数据的数据类型。例如 {‘a’: np.float64, ‘b’: np.int32}
   
   1.3 nrows : int, default None
	   需要读取的行数（从文件头开始算起）
	   
   1.4 iterator : boolean, default False
	  返回一个TextFileReader 对象，以便逐块处理文件。
 
   1.5 chunksize : int, default None
      文件块的大小， See IO Tools docs for more informationon iterator and chunksize.
   
  
2、python去两个字典的并集
    令a，b为两个字典，则计算并集c的最快方法为：
	c = dict(a, **b) 
	
3、将数据打乱 <http://blog.csdn.net/qq_22238533/article/details/70917102>
   最简单的方法就是采用pandas中自带的 sample这个方法。
   假设df是这个DataFrame
     df.sample(frac=1)  
	 
4、sklearn 特征降维利器 ―― PCA & TSNE 
  <http://blog.csdn.net/lanchunhui/article/details/64923702?locationNum=11&fps=1>
  
   同为降维工具，二者的主要区别在于，所在的包不同（也即机制和原理不同）
        from sklearn.decomposition import PCA
        from sklearn.manifold import TSNE
		
    因为原理不同，导致，tsne 保留下的属性信息，更具代表性，也即最能体现样本间的差异；
    TSNE 运行极慢，PCA 则相对较快；

	因此更为一般的处理，尤其在展示（可视化）高维数据时，常常先用 PCA 进行降维，再使用 tsne：

	data_pca = PCA(n_components=50).fit_transform(data)
	data_pca_tsne = TSNE(n_components=2).fit_transform(data_pca)
	   
	   
5、pd.DataFrame的行、列索引设置
     df = pd.read_csv('filename')
	 
    5.1 设置列索引
	    假若想自己定义列索引：
       df1 = pd.DataFrame(arr1,columns=['*','&',。。。,'%'])  # 通过columns参数设置列索引，
	   
	   假若想要df1使用df的行索引：
	    df1 = pd.DataFrame(arr1,columns=df.index) 
	   
    5.2 设置行索引  
       假若想自己定义行索引：
	   df2 = pd.DataFrame(arr2,index=['&',。。。,'%'])      # 通过参数index设置行索引
	   
	   假若想要df2的使用df1的行索引，则为：
	   df2 = pd.DataFrame(arr2,index=df1.index)      # 通过参数index设置行索引
   
    5.3 读取文件的m行至(m+n)行
       df = pd.read_csv('xiaomiappmessage.txt',names=['领域','app_name'],skiprows=10,nrows=20) 
	         #花略前10行。从第10开始，读取20行数据
          skiprows : list-like or integer, default None
             需要忽略的行数（从文件开始处算起），或需要跳过的行号列表（从0开始）。
          nrows : int, default None
			 需要读取的行数（从文件头开始算起）。    
    
   
6、有的时候，操作大文件，或者取数，要很久，我们给脚本首尾添加一段代码就知道，这段代码整体的大致运行时间了   
    import time
	start =time.clock()

	###中间写上代码块###

	end = time.clock()
	print('Running time: %s Seconds'%(end-start))
	   
   运行结果会是这样：
	  In [2]: %run F:\\celueji\\python_script\\sheetcopy_RuleRepor.py
	          ...: 
			  Running time: 443.52740769630543 Seconds
   
   
   
7、从两个DataFrame抽出两列df_1,df_2，每列的长度都相同。将它们合并在一块（左右） 
    df_result = pd.concat([df_1,df_2],axis=1)
   
   
8、读取两个csv文件,df1有列表头，df2没有列表头，将df1的列表头用在df2上面
	   df1 = pd.read_csv('test1.csv')
	   df2 = pd.read_csv('test2.csv',names = df1.columns)

9、pandas写入csv文件不要带索引，否则下次读取该文件时第一列会是Unamed，多余的。   
   save.to_csv('b.txt',index=False)
   
   
10. 有一个表，表名为test_data.csv
			age   name   pet  salary     sex
		0     4   john   cat       4    male
		1     6   wang   dog       5  female
		2     4   john   cat       4    male
		3     6     li   dog       5  female
		4     3  zhang   dog       1    male
		5     3   wang  fish       1  female
		6     6     li   dog       5  female
		7     3  zhang   dog       1    male
		8     3   wang  fish       1  female
		9     6   wang   dog       5  female
		10    3  zhang   dog       1    male
		11    3     li  fish       1  female
		12    6   wang   dog       5  female
		13    3  zhang   dog       1    male
		14    3   wang  fish       1  female
   
    df_test = pd.read_csv('test_data.csv')
	
	10.1 基于name列中，每个名字取最多取3条数据 <注：若名字个数出现不足3个，就都取。若名字个数大于3个，取前3条>
	   df_result =pd.DataFrame(np.array(df_test.groupby("device_id",as_index=False).apply(lambda x:x[:5])))
	
    10.2 基于name列，取表中所有name个数大约等于3个的数据  <注：即只要name个数>=3个，就都去取>
	   df_result = df_test[df_test.groupby('name')['name'].transform('count')>=3]
	   

#################################### pandas && groupby && apply ##############################
#################################### pandas &&  分组   &&  聚合  ##############################

11、

















